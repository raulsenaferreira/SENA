{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7b345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 20:37:36.340470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/rsenaferre/anaconda3_new/envs/ANITI_RuntimeMonitoringBenchmark/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-08-02 20:37:36.340486: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from dataset import Dataset\n",
    "from feature_extractor import FeatureExtractor\n",
    "from monitors_internals import MahalanobisMonitor, GaussianMixtureMonitor, OutsideTheBoxMonitor, MaxSoftmaxProbabilityMonitor,\\\n",
    "                    MaxLogitMonitor, EnergyMonitor, ReActMonitor\n",
    "from monitors_input import SHINE_monitor, SHINE_monitor2\n",
    "from evaluation import Evaluator\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "from PIL import Image\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92863081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(threat_type, variation_type, dataset_name, mode, root_path='data'):\n",
    "   \n",
    "    x_train, y_train, x_test, y_test = None, None, None, None\n",
    "    if mode == 'train':\n",
    "        fixed_path = os.path.join(root_path,'training_set',threat_type,variation_type)\n",
    "        if dataset_name != None:\n",
    "            fixed_path = os.path.join(root_path,'training_set',threat_type,dataset_name,variation_type)\n",
    "\n",
    "        print('loading data from', fixed_path)\n",
    "        train_images = os.path.join(fixed_path,'train-images-npy.gz')\n",
    "        train_labels = os.path.join(fixed_path,'train-labels-npy.gz')\n",
    "\n",
    "        f = gzip.GzipFile(train_images, \"r\")\n",
    "        x_train = np.load(f)\n",
    "        \n",
    "        f = gzip.GzipFile(train_labels, \"r\")\n",
    "        y_train = np.load(f)\n",
    "\n",
    "    elif mode == 'test':\n",
    "        fixed_path = os.path.join(root_path,'benchmark_dataset',threat_type,variation_type)\n",
    "        if dataset_name != None:\n",
    "            fixed_path = os.path.join(root_path,'benchmark_dataset',threat_type,dataset_name,variation_type)        \n",
    "        print('loading data from', fixed_path)\n",
    "        test_images = os.path.join(fixed_path,'test-images-npy.gz')\n",
    "        test_labels = os.path.join(fixed_path,'test-labels-npy.gz')\n",
    "\n",
    "        f = gzip.GzipFile(test_images, \"r\")\n",
    "        x_test = np.load(f)\n",
    "\n",
    "        f = gzip.GzipFile(test_labels, \"r\")\n",
    "        y_test = np.load(f)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b01c21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/training_set/distributional_shift/cifar10/snow_severity_1\n",
      "(50000, 32, 32, 3) (50000,)\n",
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/snow_severity_1\n",
      "(70000, 32, 32, 3) (70000,)\n"
     ]
    }
   ],
   "source": [
    "#model params\n",
    "batch_size = 10\n",
    "model = \"resnet\"\n",
    "\n",
    "#monitor params\n",
    "layer_relu_ids = [32]\n",
    "additional_transform = None\n",
    "adversarial_attack = None#\n",
    "\n",
    "#id dataset params\n",
    "id_dataset = \"cifar10\"\n",
    "num_classes_id = 10\n",
    "(id_X_train, id_y_train), (_, _) = load_dataset(\n",
    "    threat_type, compl_path, id_dataset, 'train', root_path='../PRDC_2021_Data_profile_module/data')#utils.load_data(id_dataset, None)\n",
    "id_X_train = id_X_train.astype('float32')\n",
    "print(np.shape(id_X_train), np.shape(id_y_train))\n",
    "\n",
    "#ood dataset params\n",
    "threat_type = 'distributional_shift'\n",
    "variation = 'snow'\n",
    "severity = 1\n",
    "compl_path = '{}_severity_{}'.format(variation, severity)\n",
    "\n",
    "(_, _), (ood_X_test, ood_y_test) = load_dataset(\n",
    "    threat_type, compl_path, id_dataset, 'test', root_path='../PRDC_2021_Data_profile_module/data')\n",
    "#correcting classes (for ood) from threat generator\n",
    "ood_y_test = [y-num_classes_id if y >= num_classes_id else y for y in ood_y_test ]\n",
    "ood_X_test = ood_X_test.astype('float32')\n",
    "#ood_X_test /= 255\n",
    "\n",
    "print(np.shape(ood_X_test), np.shape(ood_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31196a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting custom numpy data to pytorch dataset (for operations with ML models built with pytorch)\n",
    "def numpy_to_pytorch_dataset(X, y):\n",
    "    t_X = X.transpose((0, 3, 1, 2))\n",
    "    tensor_x = torch.Tensor(t_X) # transform to torch tensor\n",
    "    tensor_y = torch.Tensor(y)\n",
    "    dataset = TensorDataset(tensor_x,tensor_y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdeda56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a6f8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_data = (id_X_train, id_y_train) #numpy_to_pytorch_dataset(id_X_train, id_y_train)\n",
    "#test_data = (id_X_test, id_y_test) #numpy_to_pytorch_dataset(id_X_test, id_y_test)\n",
    "ood_data = (ood_X_test, ood_y_test) #numpy_to_pytorch_dataset(ood_X_test, ood_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9261de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset(id_dataset, \"train\", model, traning_data, batch_size=batch_size)\n",
    "#dataset_test = Dataset(id_dataset, \"test\", model, test_data, batch_size=batch_size)\n",
    "dataset_ood = Dataset(compl_path, \"test\", model, ood_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05e477b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [01:11<00:00, 70.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7000/7000 [01:45<00:00, 66.13it/s]\n"
     ]
    }
   ],
   "source": [
    "#extracting and storing features from ID and OOD data using an ML model trained on ID data\n",
    "feature_extractor = FeatureExtractor(model, id_dataset, layer_relu_ids)\n",
    "\n",
    "features_train, logits_train, softmax_train, pred_train, lab_train = feature_extractor.get_features(dataset_train)\n",
    "#features_test, logits_test, softmax_test, pred_test, lab_test = feature_extractor.get_features(dataset_test)\n",
    "features_ood, logits_ood, softmax_ood, pred_ood, lab_ood = feature_extractor.get_features(dataset_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "376359d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training:   0.99746\n",
      "Test:  0.5744857142857143\n"
     ]
    }
   ],
   "source": [
    "#accuracy of the ML model \n",
    "id_accuracy = accuracy_score(lab_train, pred_train)\n",
    "ood_accuracy = accuracy_score(lab_ood, pred_ood)\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"Training:  \", id_accuracy)\n",
    "print(\"Test: \", ood_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
