{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4b6b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision.models.feature_extraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ec89387de3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonitors_internals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMahalanobisMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGaussianMixtureMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutsideTheBoxMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxSoftmaxProbabilityMonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mMaxLogitMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnergyMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReActMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/ANITI_RuntimeMonitoringBenchmark/feature_extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_feature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchattacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.models.feature_extraction'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from dataset import Dataset\n",
    "from feature_extractor import FeatureExtractor\n",
    "from monitors_internals import MahalanobisMonitor, GaussianMixtureMonitor, OutsideTheBoxMonitor, MaxSoftmaxProbabilityMonitor,\\\n",
    "                    MaxLogitMonitor, EnergyMonitor, ReActMonitor\n",
    "from monitors_input import SHINE_monitor, SHINE_monitor2\n",
    "from evaluation import Evaluator\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params\n",
    "batch_size = 10\n",
    "model = \"resnet\"\n",
    "\n",
    "#monitor params\n",
    "layer_relu_ids = [32]\n",
    "additional_transform = None\n",
    "adversarial_attack = None#\n",
    "\n",
    "#dataset params\n",
    "id_dataset = \"cifar10\"\n",
    "ood_dataset = \"svhn\"\n",
    "(id_X_train, id_y_train), (id_X_test, id_y_test) = utils.load_data(id_dataset, None)\n",
    "(ood_X_train, ood_y_train), (ood_X_test, ood_y_test) = utils.load_data(ood_dataset, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebaee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "#loading data in pytorch way (for operations with ML models built with pytorch)\n",
    "tensor_x = torch.Tensor(id_X_train) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(id_y_train)\n",
    "\n",
    "my_trainset = TensorDataset(tensor_x,tensor_y)\n",
    "my_trainset.name = id_dataset\n",
    "my_trainset.split=\"train\"\n",
    "my_trainset.network=model\n",
    "my_trainset.additional_transform=None\n",
    "my_trainset.adversarial_attack=None\n",
    "my_trainset.batch_size=batch_size\n",
    "\n",
    "#test\n",
    "tensor_x = torch.Tensor(id_X_test) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(id_y_test)\n",
    "my_testset = TensorDataset(tensor_x,tensor_y)\n",
    "my_testset.name = id_dataset\n",
    "my_testset.split=\"test\"\n",
    "my_testset.network=model\n",
    "my_testset.additional_transform=None\n",
    "my_testset.adversarial_attack=None\n",
    "my_testset.batch_size=batch_size\n",
    "\n",
    "#ood\n",
    "tensor_x = torch.Tensor(id_X_test) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(id_y_test)\n",
    "my_dataset_ood = TensorDataset(tensor_x,tensor_y)\n",
    "my_dataset_ood.name = ood_dataset\n",
    "my_dataset_ood.split=\"test\"\n",
    "my_dataset_ood.network=model\n",
    "my_dataset_ood.additional_transform=None\n",
    "my_dataset_ood.adversarial_attack=None\n",
    "my_dataset_ood.batch_size=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712193e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting and storing features from ID and OOD data using an ML model trained on ID data\n",
    "feature_extractor = FeatureExtractor(model, id_dataset, layer_relu_ids)\n",
    "\n",
    "features_train, logits_train, softmax_train, pred_train, lab_train = feature_extractor.get_features(my_trainset)\n",
    "features_test, logits_test, softmax_test, pred_test, lab_test = feature_extractor.get_features(my_testset)\n",
    "features_ood, logits_ood, softmax_ood, pred_ood, lab_ood = feature_extractor.get_features(my_dataset_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d21f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the ML model \n",
    "id_accuracy = accuracy_score(lab_test, pred_test)\n",
    "ood_accuracy = 0\n",
    "if id_dataset == ood_dataset:\n",
    "    ood_accuracy = accuracy_score(lab_ood, pred_ood)\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"ID:  \", id_accuracy)\n",
    "print(\"OOD: \", ood_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2db5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_layer_monitored = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building SHINE monitor 2 with ID data\n",
    "monitor_shine_F = SHINE_monitor2(id_dataset)\n",
    "#monitor_shine.fit_by_class_parallel(X_train, y_train)\n",
    "monitor_shine_F.fit_by_class(id_X_train, id_y_train, pred_train)\n",
    "\n",
    "print('number of monitors',len(monitor_shine_F.arr_density))\n",
    "\n",
    "#building SHINE monitor with ID data\n",
    "monitor_shine = SHINE_monitor(id_dataset)\n",
    "#monitor_shine.fit_by_class_parallel(X_train, y_train)\n",
    "monitor_shine.fit_by_class(id_X_train, id_y_train)\n",
    "\n",
    "print('number of monitors',len(monitor_shine.arr_density))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building oob monitor\n",
    "monitor_oob = OutsideTheBoxMonitor(n_clusters=3)\n",
    "monitor_oob.fit(features_train[id_layer_monitored], lab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ca152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70099f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#between 0 and 1, percentage of ID data to be preserved\n",
    "threshold_id = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cf4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(id_X_test), np.shape(pred_test), np.shape(id_y_test.flatten()))\n",
    "#testing SHINE  and OOB monitors monitors on ID testset\n",
    "m_true = []\n",
    "m_pred = []\n",
    "m_shine_F = []\n",
    "m_oob = []\n",
    "\n",
    "for x, pred, feature, label in tqdm(zip(id_X_test, pred_test, \n",
    "                                        features_test[id_layer_monitored], id_y_test.flatten())):\n",
    "    #shine\n",
    "    monitor_pred, pdf = monitor_shine.predict(np.array([x]), pred, threshold_id)\n",
    "    m_pred.append(monitor_pred)\n",
    "    \n",
    "    #shine 2\n",
    "    monitor_F_pred, pdf = monitor_shine_F.predict(np.array([x]), pred, threshold_id)\n",
    "    m_shine_F.append(monitor_F_pred)\n",
    "    \n",
    "    #oob\n",
    "    out_box = monitor_oob.predict([feature], [pred])\n",
    "    m_oob.append(out_box)\n",
    "    \n",
    "    if pred == label: #monitor does not need to activate\n",
    "        m_true.append(0)\n",
    "    else: #monitor should activate\n",
    "        m_true.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad23c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing SHINE monitors on entire OOD dataset\n",
    "#X_ood = np.vstack([ood_X_train, ood_X_test])\n",
    "#y_ood = np.hstack([ood_y_train, ood_y_test])\n",
    "print(np.shape(ood_X_test), np.shape(ood_y_test), np.shape(pred_ood))\n",
    "\n",
    "for x, feature, pred in zip(ood_X_test, features_ood[id_layer_monitored], pred_ood):\n",
    "    #shine\n",
    "    monitor_pred, pdf = monitor_shine.predict(np.array([x]), pred, threshold_id)\n",
    "    m_pred.append(monitor_pred)\n",
    "    \n",
    "    #shine 2\n",
    "    monitor_F_pred, pdf = monitor_shine_F.predict(np.array([x]), pred, threshold_id)\n",
    "    m_shine_F.append(monitor_F_pred)\n",
    "    \n",
    "    #oob\n",
    "    out_box = monitor_oob.predict([feature], [pred])\n",
    "    m_oob.append(out_box)\n",
    "    \n",
    "    m_true.append(1) #monitor should always react to novel classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "m_true = np.array(m_true)\n",
    "m_pred = np.array(m_pred).flatten()\n",
    "m_oob = np.array(m_oob).flatten()\n",
    "\n",
    "\n",
    "#evaluating SHINE\n",
    "print('\\nSHNE')\n",
    "print(classification_report(m_true, m_pred))\n",
    "print(mcc(m_true, m_pred))\n",
    "print(balanced_accuracy_score(m_true, m_pred))\n",
    "\n",
    "#evaluating SHINE 2\n",
    "print('\\nSHINE 2')\n",
    "print(classification_report(m_true, m_shine_F))\n",
    "print(mcc(m_true, m_shine_F))\n",
    "print(balanced_accuracy_score(m_true, m_shine_F))\n",
    "\n",
    "#evaluating OOB\n",
    "print('\\nOOB')\n",
    "print(classification_report(m_true, m_oob))\n",
    "print(mcc(m_true, m_oob))\n",
    "print(balanced_accuracy_score(m_true, m_oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7fa56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
