{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4b6b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision.models.feature_extraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53c40494fc9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonitors_internals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMahalanobisMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGaussianMixtureMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutsideTheBoxMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxSoftmaxProbabilityMonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mMaxLogitMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnergyMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReActMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/ANITI_RuntimeMonitoringBenchmark/feature_extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_feature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchattacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.models.feature_extraction'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from dataset import Dataset\n",
    "from feature_extractor import FeatureExtractor\n",
    "from monitors_internals import MahalanobisMonitor, GaussianMixtureMonitor, OutsideTheBoxMonitor, MaxSoftmaxProbabilityMonitor,\\\n",
    "                    MaxLogitMonitor, EnergyMonitor, ReActMonitor\n",
    "from monitors_input import SHINE_monitor, SHINE_monitor2\n",
    "from evaluation import Evaluator\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "from PIL import Image\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params\n",
    "batch_size = 10\n",
    "model = \"resnet\"\n",
    "\n",
    "#monitor params\n",
    "layer_relu_ids = [32]\n",
    "additional_transform = None\n",
    "adversarial_attack = None#\n",
    "\n",
    "#dataset params\n",
    "id_dataset = \"cifar10\"\n",
    "ood_dataset = \"svhn\"\n",
    "(id_X_train, id_y_train), (id_X_test, id_y_test) = utils.load_data(id_dataset, None)\n",
    "(ood_X_train, ood_y_train), (ood_X_test, ood_y_test) = utils.load_data(ood_dataset, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebaee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data in pytorch way (for operations with ML models built with pytorch)\n",
    "\n",
    "tensor_x = torch.Tensor(id_X_train) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(id_y_train)\n",
    "\n",
    "my_trainset = TensorDataset(tensor_x,tensor_y)\n",
    "my_trainset.name = id_dataset\n",
    "my_trainset.split=\"train\"\n",
    "my_trainset.network=model\n",
    "my_trainset.additional_transform=None\n",
    "my_trainset.adversarial_attack=None\n",
    "my_trainset.batch_size=batch_size\n",
    "\n",
    "#test\n",
    "tensor_x = torch.Tensor(id_X_test) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(id_y_test)\n",
    "my_testset = TensorDataset(tensor_x,tensor_y)\n",
    "my_testset.name = id_dataset\n",
    "my_testset.split=\"test\"\n",
    "my_testset.network=model\n",
    "my_testset.additional_transform=None\n",
    "my_testset.adversarial_attack=None\n",
    "my_testset.batch_size=batch_size\n",
    "\n",
    "#ood\n",
    "tensor_x = torch.Tensor(id_X_test) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(id_y_test)\n",
    "my_dataset_ood = TensorDataset(tensor_x,tensor_y)\n",
    "my_dataset_ood.name = ood_dataset\n",
    "my_dataset_ood.split=\"test\"\n",
    "my_dataset_ood.network=model\n",
    "my_dataset_ood.additional_transform=None\n",
    "my_dataset_ood.adversarial_attack=None\n",
    "my_dataset_ood.batch_size=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712193e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting and storing features from ID and OOD data using an ML model trained on ID data\n",
    "feature_extractor = FeatureExtractor(model, id_dataset, layer_relu_ids)\n",
    "\n",
    "features_train, logits_train, softmax_train, pred_train, lab_train = feature_extractor.get_features(my_trainset)\n",
    "features_test, logits_test, softmax_test, pred_test, lab_test = feature_extractor.get_features(my_testset)\n",
    "features_ood, logits_ood, softmax_ood, pred_ood, lab_ood = feature_extractor.get_features(my_dataset_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d21f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the ML model \n",
    "id_accuracy = accuracy_score(lab_test, pred_test)\n",
    "ood_accuracy = 0\n",
    "if id_dataset == ood_dataset:\n",
    "    ood_accuracy = accuracy_score(lab_ood, pred_ood)\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"ID:  \", id_accuracy)\n",
    "print(\"OOD: \", ood_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2db5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_layer_monitored = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import pickle\n",
    "filename_c = 'Features/RESNET/cifar10_{}_correct.sav'\n",
    "filename_i = 'Features/RESNET/cifar10_{}_incorrect.sav'\n",
    "\n",
    "def similarity_act_func(features, id_y_train, pred_train):\n",
    "    for cls in range(10):\n",
    "        scores_1 = []\n",
    "        scores_2 = []\n",
    "        \n",
    "\n",
    "        #all labels from class c\n",
    "        ind_y_c = np.where(id_y_train == cls)[0]\n",
    "        #print('len all labels class',c, np.shape(ind_y_c), ind_y_c)\n",
    "\n",
    "        #all pred as c\n",
    "        ind_ML_c = np.where(pred_train==cls)[0]\n",
    "        #print('len pred class',c, np.shape(ind_ML_c), ind_ML_c)\n",
    "\n",
    "        #features from correct pred\n",
    "        ind = set(ind_y_c).intersection(ind_ML_c)\n",
    "        f_c_correct = features[list(ind)]\n",
    "\n",
    "        #features from incorrect pred\n",
    "        ind = set(ind_y_c).symmetric_difference(ind_ML_c)\n",
    "        f_c_incorrect = features[list(ind)]\n",
    "\n",
    "        # how similar are act functions between themselves?\n",
    "        for i in f_c_incorrect:\n",
    "            for c in f_c_correct:\n",
    "                cosine_similarity = 1 - spatial.distance.cosine(c, i)\n",
    "                scores_1.append(cosine_similarity)\n",
    "\n",
    "        for i in range(1,len(f_c_correct)):\n",
    "            cosine_similarity = 1 - spatial.distance.cosine(f_c_correct[i-1], f_c_correct[i])\n",
    "            scores_2.append(cosine_similarity)\n",
    "            \n",
    "        pickle.dump(scores_1, open(filename_i.format(cls), 'wb'))\n",
    "        pickle.dump(scores_2, open(filename_c.format(cls), 'wb'))\n",
    "\n",
    "        print('sim correct/incorrect pred', np.sum(scores_1)/len(scores_1))\n",
    "        print('sim between pairs de correct pred', np.sum(scores_2)/len(scores_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf647f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set\n",
    "print('analysis for training set')\n",
    "#features = features_train[id_layer_monitored]\n",
    "#similarity_act_func(features, id_y_train, pred_train)\n",
    "\n",
    "#test set\n",
    "print('analysis for test set')\n",
    "#features = features_test[id_layer_monitored]\n",
    "#similarity_act_func(features, id_y_test, pred_test)\n",
    "\n",
    "#OOD set\n",
    "print('analysis for OOD test set')\n",
    "#features = features_ood[id_layer_monitored]\n",
    "#similarity_act_func(features, ood_y_test, pred_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building SHINE monitor with ID data\n",
    "#monitor_shine = SHINE_monitor(id_dataset)\n",
    "#monitor_shine.fit_by_class_parallel(X_train, y_train)\n",
    "#monitor_shine.fit_by_class(id_X_train, id_y_train, pred_train)\n",
    "\n",
    "#print('number of monitors',len(monitor_shine.arr_density))\n",
    "\n",
    "\n",
    "#building SHINE 2 monitor with ID data\n",
    "#monitor_shine2 = SHINE_monitor2(id_dataset)\n",
    "#monitor_shine.fit_by_class_parallel(X_train, y_train)\n",
    "#monitor_shine2.fit_by_class(id_X_train, id_y_train, pred_train)\n",
    "\n",
    "#print('number of monitors',len(monitor_shine2.arr_density))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ca152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same analysis but for SHINE scores\n",
    "\n",
    "def shine_perf_analysis(id_X_train, id_y_training, pred_train, threshold_id):\n",
    "    for c in range(10):\n",
    "        scores_1 = []\n",
    "        scores_2 = []\n",
    "        #threshold_c = monitor_shine.scores_per_class[c]\n",
    "\n",
    "        #all labels from class c\n",
    "        ind_y_c = np.where(id_y_training == c)[0]\n",
    "        #print('len all labels class',c, np.shape(ind_y_c), ind_y_c)\n",
    "\n",
    "        #all pred as c\n",
    "        ind_ML_c = np.where(pred_train==c)[0]\n",
    "        #print('len pred class',c, np.shape(ind_ML_c), ind_ML_c)\n",
    "\n",
    "        #images from correct pred\n",
    "        ind = set(ind_y_c).intersection(ind_ML_c)\n",
    "        X_c_correct = id_X_train[list(ind)]\n",
    "\n",
    "        #scores from correct\n",
    "        for x, pred in zip(X_c_correct, pred_train[list(ind)]):\n",
    "            monitor_pred, pdf = monitor_shine.predict(np.array([x]), pred, threshold_id)\n",
    "            scores_1.append(monitor_pred)\n",
    "\n",
    "        #images from incorrect pred\n",
    "        ind = set(ind_y_c).symmetric_difference(ind_ML_c)\n",
    "        X_c_incorrect = id_X_train[list(ind)]\n",
    "\n",
    "        #scores from incorrect\n",
    "        for x, pred in zip(X_c_incorrect, pred_train[list(ind)]):\n",
    "            monitor_pred, pdf = monitor_shine.predict(np.array([x]), pred, threshold_id)\n",
    "            scores_2.append(monitor_pred)\n",
    "\n",
    "        print('avg score for correct pred', 1-(np.sum(scores_1)/len(scores_1)))\n",
    "        print('avg score for incorrect pred', 1-(np.sum(scores_2)/len(scores_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70099f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_id = 0.9\n",
    "\n",
    "#training set\n",
    "print('training set analysis')\n",
    "#shine_perf_analysis(id_X_train, id_y_train, pred_train, threshold_id)\n",
    "\n",
    "#testing set\n",
    "print('testing set analysis')\n",
    "#shine_perf_analysis(id_X_test, id_y_test, pred_test, threshold_id)\n",
    "\n",
    "#testing set\n",
    "print('OOD test set analysis')\n",
    "#shine_perf_analysis(ood_X_test, ood_y_test, pred_ood, threshold_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cf4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hybrid version of SHINE\n",
    "arr_ood_threshold = {}\n",
    "#arr_ood_threshold.update({0: 0.7043, 1: 0.7919, 2: 0.6996, 3: 0.7209, 4:0.7435, 5:0.7924, 6:0.6745, 7:0.7481,\n",
    "#                         8:0.6934, 9:0.7831})\n",
    "arr_ood_threshold.update({0: 0.7, 1: 0.7, 2: 0.6, 3: 0.7, 4:0.7, 5:0.7, 6:0.6, 7:0.7, 8:0.6, 9:0.7})\n",
    "\n",
    "arr_id_threshold = {}\n",
    "arr_id_threshold.update({0:0.9499, 1:0.9692, 2:0.9494, 3:0.9340, 4:0.9624, 5:0.9582, 6:0.9417, 7:0.9641,\n",
    "                        8:0.9695, 9:0.9695})\n",
    "\n",
    "#arr_id_threshold.update({0:0.94, 1:0.96, 2:0.94, 3:0.93, 4:0.96, 5:0.95, 6:0.94, 7:0.96, 8:0.96, 9:0.96})\n",
    "\n",
    "def run_new_SHINE(monitor_shine, X, pred, incoming_feature, threshold_shine):\n",
    "    features = features_train[id_layer_monitored]\n",
    "    #all labels from class c\n",
    "    ind_y_c = np.where(id_y_train == pred)[0]\n",
    "    #print('len all labels class',c, np.shape(ind_y_c), ind_y_c)\n",
    "\n",
    "    #all pred as c\n",
    "    ind_ML_c = np.where(pred_train==pred)[0]\n",
    "    #print('len pred class',c, np.shape(ind_ML_c), ind_ML_c)\n",
    "\n",
    "    #features from correct pred\n",
    "    ind = set(ind_y_c).intersection(ind_ML_c)\n",
    "    f_c_correct = features[list(ind)]\n",
    "\n",
    "    scores = []\n",
    "    for c in f_c_correct:\n",
    "        cosine_similarity = 1 - spatial.distance.cosine(c, incoming_feature)\n",
    "        scores.append(cosine_similarity)\n",
    "        \n",
    "    avg_sim = np.sum(scores)/len(scores)\n",
    "    \n",
    "    if avg_sim >= arr_id_threshold[pred]:\n",
    "        return False #it is ID and correct pred\n",
    "    elif avg_sim < arr_ood_threshold[pred]:\n",
    "        return True #it is OOD\n",
    "    else:\n",
    "        #it is not OOD but we do not know if the prediction is correct\n",
    "        monitor_pred, pdf = monitor_shine.predict(X, pred, threshold_shine)\n",
    "        return monitor_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f36fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## experimenting new thresholds for shine\n",
    "def run_SHINE_2(monitor_shine, X, pred, incoming_feature, threshold_SMimg, threshold_SMout):\n",
    "    features = features_train[id_layer_monitored]\n",
    "    #all labels from class c\n",
    "    ind_y_c = np.where(id_y_train == pred)[0]\n",
    "    #print('len all labels class',c, np.shape(ind_y_c), ind_y_c)\n",
    "\n",
    "    #all pred as c\n",
    "    ind_ML_c = np.where(pred_train==pred)[0]\n",
    "    #print('len pred class',c, np.shape(ind_ML_c), ind_ML_c)\n",
    "\n",
    "    #features from correct pred\n",
    "    ind = set(ind_y_c).intersection(ind_ML_c)\n",
    "    f_c_correct = features[list(ind)]\n",
    "\n",
    "    scores = []\n",
    "    for c in f_c_correct:\n",
    "        cosine_similarity = 1 - spatial.distance.cosine(c, incoming_feature)\n",
    "        scores.append(cosine_similarity)\n",
    "        \n",
    "    len_scores = len(scores)\n",
    "    sorted_scores = sorted(scores)\n",
    "    ind_threshold = int(len_scores*threshold_SMout)\n",
    "    min_threshold_sim = sorted_scores[-ind_threshold]\n",
    "    max_threshold_sim = sorted_scores[ind_threshold]\n",
    "    #avg_sim = np.sum(scores)/len(scores)\n",
    "    \n",
    "    if max_threshold_sim >= arr_id_threshold[pred]:\n",
    "        return False #it is ID and correct pred\n",
    "    elif min_threshold_sim <= arr_ood_threshold[pred]:\n",
    "        return True #it is OOD\n",
    "    else:\n",
    "        #it is not OOD but we do not know if the prediction is correct\n",
    "        monitor_pred, pdf = monitor_shine.predict(X, pred, threshold_SMimg)\n",
    "        return monitor_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building oob monitor\n",
    "monitor_oob = OutsideTheBoxMonitor(n_clusters=3)\n",
    "monitor_oob.fit(features_train[id_layer_monitored], lab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a573c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building react monitor\n",
    "monitor_react = ReActMonitor(quantile_value=0.99, mode='msp')\n",
    "monitor_react.fit(feature_extractor, features_train[id_layer_monitored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023290a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building softmax monitor\n",
    "monitor_msp = MaxSoftmaxProbabilityMonitor()\n",
    "monitor_msp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building max logit monitor\n",
    "monitor_maxlogits = MaxLogitMonitor()\n",
    "monitor_maxlogits.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building Energy monitor\n",
    "T = 1\n",
    "monitor_energy = EnergyMonitor(temperature=T)\n",
    "monitor_energy.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd41ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building mahalanobis monitor\n",
    "monitor_mahalanobis = MahalanobisMonitor(id_dataset, model, id_layer_monitored, is_tied=False)\n",
    "monitor_mahalanobis.fit(features_train[id_layer_monitored], lab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad23c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing SHINE  and OOB monitors monitors on ID testset\n",
    "m_true = []\n",
    "m_shine = []\n",
    "m_shine_2 = []\n",
    "m_oob = []\n",
    "m_react = []\n",
    "m_msp = []\n",
    "m_logits = []\n",
    "m_energy = []\n",
    "m_mhlnbis = []\n",
    "\n",
    "threshold_SMimg = 0.1\n",
    "threshold_SMout = 0.9\n",
    "\n",
    "for x, pred, feature, softmax, logits, label in tqdm(zip(id_X_test, pred_test, features_test[id_layer_monitored],\n",
    "                                                 softmax_test, logits_test, id_y_test.flatten())):\n",
    "    #SHINE\n",
    "    #monitor_shine_pred = run_new_SHINE(monitor_shine2, np.array([x]), pred, feature, threshold_id)\n",
    "    #m_shine.append(monitor_shine_pred)\n",
    "    \n",
    "    # SHINE relaxed thresholds\n",
    "    #monitor_shine_pred_2 = run_SHINE_2(monitor_shine2, np.array([x]), pred, feature,\n",
    "    #                                   threshold_SMimg, threshold_SMout)\n",
    "    #m_shine_2.append(monitor_shine_pred_2)\n",
    "    \n",
    "    #oob\n",
    "    out_box = monitor_oob.predict([feature], [pred])\n",
    "    m_oob.append(out_box)\n",
    "    \n",
    "    #react\n",
    "    r = monitor_react.predict([feature])\n",
    "    m_react.append(r)\n",
    "    \n",
    "    #Max Softmax Probability\n",
    "    msp = monitor_msp.predict([softmax])\n",
    "    m_msp.append(msp)\n",
    "    \n",
    "    #Max logit\n",
    "    maxlogits = monitor_maxlogits.predict([logits])\n",
    "    m_logits.append(maxlogits)\n",
    "    \n",
    "    #Energy\n",
    "    energy = monitor_energy.predict(logits)\n",
    "    m_energy.append(energy)\n",
    "    \n",
    "    #mahalanobis\n",
    "    #mahalanobis = monitor_mahalanobis.predict(np.array([feature]), [pred])\n",
    "    #m_mhlnbis.append(mahalanobis)\n",
    "    \n",
    "    if pred == label: #monitor does not need to activate\n",
    "        m_true.append(False)\n",
    "    else: #monitor should activate\n",
    "        m_true.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, feature, softmax, logits, pred in tqdm(zip(ood_X_test, features_ood[id_layer_monitored], softmax_ood,\n",
    "                                          logits_ood, pred_ood)):\n",
    "    #SHINE\n",
    "    #monitor_shine_pred = run_new_SHINE(monitor_shine2, np.array([x]), pred, feature, threshold_id)\n",
    "    #m_shine.append(monitor_shine_pred)\n",
    "    \n",
    "    # SHINE relaxed thresholds\n",
    "    #monitor_shine_pred_2 = run_SHINE_2(monitor_shine2, np.array([x]), pred, feature,\n",
    "    #                                   threshold_SMimg, threshold_SMout)\n",
    "    #m_shine_2.append(monitor_shine_pred_2)\n",
    "    \n",
    "    #oob\n",
    "    out_box = monitor_oob.predict([feature], [pred])\n",
    "    m_oob.append(out_box)\n",
    "    \n",
    "    #react\n",
    "    r = monitor_react.predict([feature])\n",
    "    m_react.append(r)\n",
    "    \n",
    "    #Max Softmax Probability\n",
    "    msp = monitor_msp.predict([softmax])\n",
    "    m_msp.append(msp)\n",
    "    \n",
    "    #Max logit\n",
    "    maxlogits = monitor_maxlogits.predict([logits])\n",
    "    m_logits.append(maxlogits)\n",
    "    \n",
    "    #Energy\n",
    "    energy = monitor_energy.predict(logits)\n",
    "    m_energy.append(energy)\n",
    "    \n",
    "    #mahalanobis\n",
    "    #mahalanobis = monitor_mahalanobis.predict([feature], [pred])\n",
    "    #m_mhlnbis.append(mahalanobis)\n",
    "    \n",
    "    m_true.append(True) #monitor should always react to novel classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "m_true = np.array(m_true).astype(bool)\n",
    "#m_shine = np.array(m_shine).astype(bool)\n",
    "#m_shine_2 = np.array(m_shine_2).astype(bool)\n",
    "m_oob = np.array(m_oob).astype(bool)\n",
    "m_react = np.array(m_react).astype(bool)\n",
    "m_msp = np.array(m_msp).astype(bool)\n",
    "m_logits = np.array(m_logits).astype(bool)\n",
    "m_energy = np.array(m_energy).astype(bool)\n",
    "m_mhlnbis = np.array(m_mhlnbis).astype(bool)\n",
    "\n",
    "#evaluating new SHINE \n",
    "#print('\\nSHINE new')\n",
    "#print(classification_report(m_true, m_shine))\n",
    "#print(mcc(m_true, m_shine))\n",
    "#print(balanced_accuracy_score(m_true, m_shine))\n",
    "\n",
    "#evaluating new SHINE 2\n",
    "#print('\\nSHINE new 2')\n",
    "#print(classification_report(m_true, m_shine_2))\n",
    "#print(mcc(m_true, m_shine_2))\n",
    "#print(balanced_accuracy_score(m_true, m_shine_2))\n",
    "\n",
    "#evaluating OOB\n",
    "print('\\nOOB')\n",
    "print(classification_report(m_true, m_oob))\n",
    "print(mcc(m_true, m_oob))\n",
    "print(balanced_accuracy_score(m_true, m_oob))\n",
    "\n",
    "#evaluating React\n",
    "print('\\nReact')\n",
    "print(classification_report(m_true, m_react))\n",
    "print(mcc(m_true, m_react))\n",
    "print(balanced_accuracy_score(m_true, m_react))\n",
    "\n",
    "#evaluating Max Softmax probability\n",
    "print('\\nMax Softmax probability')\n",
    "print(classification_report(m_true, m_msp))\n",
    "print(mcc(m_true, m_msp))\n",
    "print(balanced_accuracy_score(m_true, m_msp))\n",
    "\n",
    "#evaluating Max Logits\n",
    "print('\\nMax Logits')\n",
    "print(classification_report(m_true, m_logits))\n",
    "print(mcc(m_true, m_logits))\n",
    "print(balanced_accuracy_score(m_true, m_logits))\n",
    "\n",
    "#evaluating Energy\n",
    "print('\\nEnergy')\n",
    "print(classification_report(m_true, m_energy))\n",
    "print(mcc(m_true, m_energy))\n",
    "print(balanced_accuracy_score(m_true, m_energy))\n",
    "\n",
    "#evaluating Mahalanobis\n",
    "#print('\\nMahalanobis')\n",
    "#print(classification_report(m_true, m_mhlnbis))\n",
    "#print(mcc(m_true, m_mhlnbis))\n",
    "#print(balanced_accuracy_score(m_true, m_mhlnbis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "id_threshold = int(len_scores*threshold_shine)\n",
    "min_threshold_sim = sorted_scores[-id_threshold]\n",
    "max_threshold_sim = sorted_scores[id_threshold]\n",
    "\n",
    "SHINE new 2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.62      0.86      0.72      9367\n",
    "        True       0.94      0.82      0.87     26665\n",
    "\n",
    "    accuracy                           0.83     36032\n",
    "   macro avg       0.78      0.84      0.80     36032\n",
    "weighted avg       0.86      0.83      0.83     36032\n",
    "\n",
    "0.6156203195994662\n",
    "0.8364962945766474\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
