{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4b6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 14:39:56.939273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-31 14:39:56.939287: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "from dataset import Dataset\n",
    "from feature_extractor import FeatureExtractor\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3126fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_OOD_data(id_dataset, num_classes_id, threat_type, variation, severity, compl_path):\n",
    "    #loading test set\n",
    "    X_test, y_test = utils.load_dataset(\n",
    "        threat_type, compl_path, id_dataset, 'test', root_path='../PRDC_2021_Data_profile_module/data')\n",
    "    #correcting classes (for ood) from threat generator\n",
    "    y_test = [y-num_classes_id if y >= num_classes_id else y for y in y_test ]\n",
    "    X_test = X_test.astype('float32')\n",
    "    print(np.shape(X_test), np.shape(y_test))\n",
    "\n",
    "    #change here the number of instances to be used in the test\n",
    "    num_instances = len(y_test)\n",
    "    X_test, y_test = X_test[:num_instances], y_test[:num_instances]\n",
    "\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf647f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it returns an updated dictionaire containing the monitors results \n",
    "def test_monitor(arr_monitor_results, monitor, X_test, y_test, pred_test, features_test, logits_test, softmax_test):\n",
    "    \n",
    "    for X, y, pred, features, logits, softmax in tqdm(zip(X_test, y_test, pred_test, \n",
    "                                             features_test, logits_test, softmax_test)): \n",
    "\n",
    "        m_score, m_pred = None, None\n",
    "        \n",
    "        if monitor.name == 'react':\n",
    "            m_score = monitor.predict(np.array([features]))[0]\n",
    "\n",
    "        elif monitor.name == 'maxlogit' or monitor.name == 'energy':\n",
    "            m_score = monitor.predict(np.array([logits]))[0]\n",
    "\n",
    "        elif monitor.name == 'msp':\n",
    "            m_score = monitor.predict(np.array([softmax]))[0]\n",
    "\n",
    "        elif monitor.name == 'mahalanobis':\n",
    "            m_score = monitor.predict(np.array([features]), [pred])[0]\n",
    "\n",
    "        #all above methods are based on scores    \n",
    "        if m_score is not None: m_pred = m_score<=monitor.arr_thresholds[pred]\n",
    "\n",
    "        if monitor.name == 'oob':\n",
    "            m_pred = monitor.predict([features], [pred])[0]\n",
    "\n",
    "        elif monitor.name == 'shine':\n",
    "            avg_sim_TP, logprob = monitor.predict(np.array([X]), features, pred)\n",
    "\n",
    "            if avg_sim_TP >= monitor.arr_thresholds['S'][pred]['TP']:\n",
    "                m_pred = False\n",
    "            elif avg_sim_TP <= monitor.arr_thresholds['S'][pred]['FN']:\n",
    "                m_pred = True\n",
    "            else:\n",
    "                m_pred = np.exp(logprob) <= monitor.arr_thresholds['HINE'][pred]\n",
    "\n",
    "        if m_pred is not None:\n",
    "            #print('{} reacted? ... {}'.format(monitor.name, m_pred))\n",
    "            try:\n",
    "                arr_monitor_results[monitor.name].append(m_pred)\n",
    "            except:\n",
    "                arr_monitor_results.update({monitor.name: [m_pred]})\n",
    "        else:\n",
    "            print('unknown monitor')\n",
    "            return None\n",
    "\n",
    "    return arr_monitor_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9fac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/snow_severity_1\n",
      "(70000, 32, 32, 3) (70000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70000it [00:02, 28152.00it/s]\n",
      "70000it [00:04, 17387.15it/s]\n",
      "70000it [00:00, 124116.65it/s]\n",
      "70000it [00:00, 135543.36it/s]\n",
      "70000it [00:02, 28947.82it/s]\n",
      "70000it [00:01, 35890.55it/s]\n",
      "70000it [02:24, 484.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/snow_severity_2\n",
      "(70000, 32, 32, 3) (70000,)\n",
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7000/7000 [01:41<00:00, 69.21it/s]\n",
      "70000it [00:02, 24007.33it/s]\n",
      "70000it [00:04, 16882.66it/s]\n",
      "70000it [00:00, 136228.81it/s]\n",
      "70000it [00:00, 131364.81it/s]\n",
      "70000it [00:02, 27935.29it/s]\n",
      "70000it [00:01, 35917.61it/s]\n",
      "70000it [02:22, 489.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/snow_severity_3\n",
      "(70000, 32, 32, 3) (70000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70000it [00:02, 25563.10it/s]\n",
      "70000it [00:04, 17398.08it/s]\n",
      "70000it [00:00, 137775.78it/s]\n",
      "70000it [00:00, 137821.76it/s]\n",
      "70000it [00:02, 28521.03it/s]\n",
      "70000it [00:02, 31500.40it/s]\n",
      "70000it [02:21, 493.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/snow_severity_4\n",
      "(70000, 32, 32, 3) (70000,)\n",
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7000/7000 [01:39<00:00, 70.27it/s]\n",
      "70000it [00:02, 24483.84it/s]\n",
      "70000it [00:04, 17301.49it/s]\n",
      "70000it [00:00, 135899.21it/s]\n",
      "70000it [00:00, 127165.69it/s]\n",
      "70000it [00:02, 28821.20it/s]\n",
      "70000it [00:01, 35609.42it/s]\n",
      "70000it [02:22, 491.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/snow_severity_5\n",
      "(70000, 32, 32, 3) (70000,)\n",
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7000/7000 [01:40<00:00, 69.49it/s]\n",
      "70000it [00:02, 25535.54it/s]\n",
      "70000it [00:04, 17164.08it/s]\n",
      "70000it [00:00, 137175.51it/s]\n",
      "70000it [00:00, 151745.57it/s]\n",
      "70000it [00:02, 29264.05it/s]\n",
      "70000it [00:01, 38006.45it/s]\n",
      "70000it [02:22, 490.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/fog_severity_1\n",
      "(70000, 32, 32, 3) (70000,)\n",
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7000/7000 [01:40<00:00, 69.52it/s]\n",
      "70000it [00:01, 43207.27it/s]\n",
      "70000it [00:04, 17307.17it/s]\n",
      "70000it [00:00, 124624.04it/s]\n",
      "70000it [00:00, 126389.66it/s]\n",
      "70000it [00:02, 28193.40it/s]\n",
      "70000it [00:01, 36504.96it/s]\n",
      "70000it [02:23, 487.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/fog_severity_2\n",
      "(70000, 32, 32, 3) (70000,)\n",
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7000/7000 [01:41<00:00, 69.25it/s]\n",
      "70000it [00:01, 38385.21it/s]\n",
      "70000it [00:04, 17125.33it/s]\n",
      "70000it [00:00, 138341.02it/s]\n",
      "70000it [00:00, 137963.39it/s]\n",
      "70000it [00:02, 28706.21it/s]\n",
      "70000it [00:01, 37905.54it/s]\n",
      "70000it [02:21, 493.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/benchmark_dataset/distributional_shift/cifar10/fog_severity_3\n",
      "(70000, 32, 32, 3) (70000,)\n",
      "Extracting layers: 'layer4.2.relu_1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▍                          | 2224/7000 [00:32<01:08, 69.35it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### testing monitors\n",
    "#model params\n",
    "batch_size = 10\n",
    "model = \"resnet\"\n",
    "\n",
    "#monitor params\n",
    "# layer observed by monitors that uses info from activation function layer\n",
    "layer_relu_ids = [32]\n",
    "id_layer_monitored = -1\n",
    "additional_transform = None\n",
    "adversarial_attack = None#\n",
    "\n",
    "#dataset params\n",
    "id_dataset = \"cifar10\"\n",
    "num_classes_id = 10\n",
    "threat_type = 'distributional_shift'\n",
    "variations = ['snow', 'fog', 'brightness', 'saturate', 'contrast']\n",
    "severities = [1, 2, 3, 4, 5]\n",
    "\n",
    "#loading monitors\n",
    "monitor_names = ['oob','react', 'msp', 'maxlogit', 'energy', 'mahalanobis','shine']\n",
    "arr_monitors = []\n",
    "\n",
    "for name in monitor_names:\n",
    "    monitor_filename = os.path.join('Monitors', id_dataset, '{}.sav'.format(name))\n",
    "    monitor = pickle.load(open(monitor_filename, 'rb'))\n",
    "    arr_monitors.append(monitor)\n",
    "\n",
    "for variation in variations:\n",
    "    for severity in severities:\n",
    "        compl_path = '{}_severity_{}'.format(variation, severity)\n",
    "        \n",
    "        #loading OOD data\n",
    "        X_test, y_test = load_OOD_data(id_dataset, num_classes_id, threat_type, variation, severity, compl_path)\n",
    "        \n",
    "        #extracting and storing features from test data using an ML model trained on ID data\n",
    "        dataset_test = Dataset(compl_path, \"test\", model, (X_test, y_test), batch_size=batch_size)\n",
    "        feature_extractor = FeatureExtractor(model, id_dataset, layer_relu_ids)\n",
    "        features_test, logits_test, softmax_test, pred_test, lab_test = feature_extractor.get_features(dataset_test)\n",
    "        \n",
    "        arr_monitor_results = {}\n",
    "        \n",
    "        for monitor in arr_monitors:\n",
    "            print('processing', monitor.name, compl_path)\n",
    "            arr_monitor_results = test_monitor(arr_monitor_results, monitor, X_test, y_test, pred_test, \n",
    "                         features_test[id_layer_monitored], logits_test, softmax_test)\n",
    "\n",
    "        #saving results\n",
    "        filename = os.path.join('results', id_dataset, threat_type, '{}.sav'.format(compl_path))\n",
    "        pickle.dump(arr_monitor_results, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "## Ex: loading results for distributional shift snow severity 4\n",
    "file = os.path.join('results', id_dataset, threat_type, '{}.sav'.format('snow_severity_4'))\n",
    "all_results = pickle.load(open(file, 'rb'))\n",
    "## ground truth\n",
    "#if pred == y then monitor does not need to activate (False)\n",
    "#or monitor should activate otherwise (True)\n",
    "m_true = [False if pred == y else True for pred, y in zip(pred_test, y_test)]\n",
    "\n",
    "#m_true = np.array(m_true).astype(bool)\n",
    "#m_shine = np.array(m_shine).astype(bool)\n",
    "#m_shine_2 = np.array(m_shine_2).astype(bool)\n",
    "#m_oob = np.array(m_oob).astype(bool)\n",
    "#m_react = np.array(m_react).astype(bool)\n",
    "#m_msp = np.array(m_msp).astype(bool)\n",
    "#m_logits = np.array(m_logits).astype(bool)\n",
    "#m_energy = np.array(m_energy).astype(bool)\n",
    "#m_mhlnbis = np.array(m_mhlnbis).astype(bool)\n",
    "\n",
    "print('accuracy of the ML model alone')\n",
    "print('classification_report', classification_report(lab_test, pred_test))\n",
    "print('mcc', mcc(lab_test, pred_test))\n",
    "print('balanced_accuracy_score', balanced_accuracy_score(lab_test, pred_test))\n",
    "print('\\n\\n')\n",
    "\n",
    "for k,v in all_results.items():\n",
    "    print(k, 'monitor')\n",
    "    print('classification_report', classification_report(m_true, v))\n",
    "    print('mcc', mcc(m_true, v))\n",
    "    print('balanced_accuracy_score', balanced_accuracy_score(m_true, v))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "snow threshold 0.9\n",
    "0.3713363713102381\n",
    "0.640411057439756\n",
    "\n",
    "\n",
    "id_threshold = int(len_scores*threshold_shine)\n",
    "min_threshold_sim = sorted_scores[-id_threshold]\n",
    "max_threshold_sim = sorted_scores[id_threshold]\n",
    "\n",
    "SHINE new 2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.62      0.86      0.72      9367\n",
    "        True       0.94      0.82      0.87     26665\n",
    "\n",
    "    accuracy                           0.83     36032\n",
    "   macro avg       0.78      0.84      0.80     36032\n",
    "weighted avg       0.86      0.83      0.83     36032\n",
    "\n",
    "0.6156203195994662\n",
    "0.8364962945766474\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53086164",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "React\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.98      0.02      0.04     25818\n",
    "        True       0.64      1.00      0.78     44182\n",
    "\n",
    "    accuracy                           0.64     70000\n",
    "   macro avg       0.81      0.51      0.41     70000\n",
    "weighted avg       0.76      0.64      0.50     70000\n",
    "\n",
    "0.11052419184412475\n",
    "0.5098443945123656\n",
    "\n",
    "Max Softmax probability\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.00      0.00      0.00     25818\n",
    "        True       0.63      1.00      0.77     44182\n",
    "\n",
    "    accuracy                           0.63     70000\n",
    "   macro avg       0.32      0.50      0.39     70000\n",
    "weighted avg       0.40      0.63      0.49     70000\n",
    "\n",
    "0.0\n",
    "0.5\n",
    "\n",
    "Max Logits\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.37      1.00      0.54     25818\n",
    "        True       0.87      0.00      0.01     44182\n",
    "\n",
    "    accuracy                           0.37     70000\n",
    "   macro avg       0.62      0.50      0.27     70000\n",
    "weighted avg       0.69      0.37      0.20     70000\n",
    "\n",
    "0.026908422094739797\n",
    "0.5015141376479284\n",
    "\n",
    "Energy\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.58      0.65      0.62     25818\n",
    "        True       0.78      0.73      0.75     44182\n",
    "\n",
    "    accuracy                           0.70     70000\n",
    "   macro avg       0.68      0.69      0.69     70000\n",
    "weighted avg       0.71      0.70      0.70     70000\n",
    "\n",
    "0.37349132101691174\n",
    "0.6905844936380467\n",
    "\n",
    "Mahalanobis\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       1.00      0.02      0.03     25818\n",
    "        True       0.64      1.00      0.78     44182\n",
    "\n",
    "    accuracy                           0.64     70000\n",
    "   macro avg       0.82      0.51      0.41     70000\n",
    "weighted avg       0.77      0.64      0.50     70000\n",
    "\n",
    "0.10475331158410182\n",
    "0.5086373847703153\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
