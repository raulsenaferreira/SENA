{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4b6b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision.models.feature_extraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4508f07be075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonitors_internals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMahalanobisMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGaussianMixtureMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutsideTheBoxMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxSoftmaxProbabilityMonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mMaxLogitMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnergyMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReActMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/ANITI_RuntimeMonitoringBenchmark/feature_extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_feature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchattacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.models.feature_extraction'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from dataset import Dataset\n",
    "from feature_extractor import FeatureExtractor\n",
    "from monitors_internals import MahalanobisMonitor, GaussianMixtureMonitor, OutsideTheBoxMonitor, MaxSoftmaxProbabilityMonitor,\\\n",
    "                    MaxLogitMonitor, EnergyMonitor, ReActMonitor\n",
    "from monitors_input import SHINE_monitor\n",
    "from evaluation import Evaluator\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1d49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params\n",
    "batch_size = 10\n",
    "model = \"resnet\"\n",
    "\n",
    "#monitor params\n",
    "layer_relu_ids = [32]\n",
    "\n",
    "#dataset params\n",
    "id_dataset = \"cifar10\"\n",
    "ood_dataset = \"svhn\"\n",
    "\n",
    "additional_transform = None\n",
    "adversarial_attack = None#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fcc114a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "dataset_train = Dataset(id_dataset, \"train\", model, batch_size=batch_size)\n",
    "dataset_test = Dataset(id_dataset, \"test\", model, batch_size=batch_size)\n",
    "dataset_ood = Dataset(ood_dataset, \"test\", model, additional_transform, adversarial_attack, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1a8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting and storing features from ID and OOD data using an ML model trained on ID data\n",
    "feature_extractor = FeatureExtractor(model, id_dataset, layer_relu_ids)\n",
    "\n",
    "features_train, logits_train, softmax_train, pred_train, lab_train = feature_extractor.get_features(dataset_train)\n",
    "features_test, logits_test, softmax_test, pred_test, lab_test = feature_extractor.get_features(dataset_test)\n",
    "features_ood, logits_ood, softmax_ood, pred_ood, lab_ood = feature_extractor.get_features(dataset_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f2767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "ID:   0.9367\n",
      "OOD:  0\n"
     ]
    }
   ],
   "source": [
    "#accuracy of the ML model \n",
    "id_accuracy = accuracy_score(lab_test, pred_test)\n",
    "ood_accuracy = 0\n",
    "if id_dataset == ood_dataset:\n",
    "    ood_accuracy = accuracy_score(lab_ood, pred_ood)\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"ID:  \", id_accuracy)\n",
    "print(\"OOD: \", ood_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7788b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 851.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(X), np.shape(y): (50000, 32, 32, 3) (50000,)\n"
     ]
    }
   ],
   "source": [
    "# Converting training dataset (ID) from pytorch to numpy format\n",
    "num_samples = None\n",
    "\n",
    "X, y = [],[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(dataset_train.dataloader):\n",
    "        X.append(data[0].numpy())\n",
    "        y.append(data[1].numpy())\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train = np.reshape(X, (batch_size*X.shape[0], X.shape[3], X.shape[4], X.shape[2]))\n",
    "y_train = np.reshape(y, batch_size*y.shape[0])\n",
    "\n",
    "print('np.shape(X), np.shape(y):',np.shape(X_train), np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b2316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "{'bandwidth': 1.0}\n",
      "number of monitors 10\n"
     ]
    }
   ],
   "source": [
    "#building SHINE monitor with ID data\n",
    "monitor_shine = SHINE_monitor(id_dataset)\n",
    "#monitor_shine.fit_by_class_parallel(X_train, y_train)\n",
    "monitor_shine.fit_by_class(X_train, y_train)\n",
    "\n",
    "print('number of monitors',len(monitor_shine.arr_density))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "179ee232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "300435df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:01<00:00, 754.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10, 3, 32, 32) (1000, 10) (10000,)\n",
      "(10000, 32, 32, 3) (10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "## Converting test dataset (ID) from pytorch to numpy format\n",
    "X, y = [],[]\n",
    "\n",
    "for data in tqdm(dataset_test.dataloader):\n",
    "    X.append(data[0].numpy())\n",
    "    y.append(data[1].numpy())\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(np.shape(X), np.shape(y), np.shape(pred_test))\n",
    "\n",
    "X_test = np.reshape(X, (batch_size*X.shape[0], X.shape[3], X.shape[4], X.shape[2]))\n",
    "y_test = np.reshape(y, batch_size*y.shape[0])\n",
    "\n",
    "print(np.shape(X_test), np.shape(y_test), np.shape(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4db0ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#between 0 and 1, percentage of ID data to be preserved\n",
    "threshold_id = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39da5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [02:32, 326.87it/s]\n"
     ]
    }
   ],
   "source": [
    "#testing SHINE monitors on the same ID trainset (just for test purposes, one can skip this part)\n",
    "m_true = []\n",
    "m_pred = []\n",
    "\n",
    "for x, pred, label in tqdm(zip(X_train, pred_train, y_train)):\n",
    "    monitor_pred, pdf = monitor_shine.predict(np.array([x]), pred, threshold_id)\n",
    "    m_pred.append(monitor_pred)\n",
    "    \n",
    "    if pred == label: #monitor does not need to activate\n",
    "        m_true.append(0)\n",
    "    else: #monitor should activate\n",
    "        m_true.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "564492a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:31, 317.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#testing SHINE monitors on ID testset\n",
    "m_true = []\n",
    "m_pred = []\n",
    "\n",
    "for x, pred, label in tqdm(zip(X_test, pred_test, y_test)):\n",
    "    monitor_pred, pdf = monitor_shine.predict(np.array([x]), pred, threshold_id)\n",
    "    m_pred.append(monitor_pred)\n",
    "    \n",
    "    if pred == label: #monitor does not need to activate\n",
    "        m_true.append(0)\n",
    "    else: #monitor should activate\n",
    "        m_true.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b121bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2604 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_ood, pred_ood):\n\u001b[1;32m     10\u001b[0m     monitor_pred, pdf \u001b[38;5;241m=\u001b[39m monitor_shine\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([x]), pred, threshold_id)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mm_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(monitor_pred)\n\u001b[1;32m     12\u001b[0m     m_true\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# testing SHINE monitors on entire OOD dataset\n",
    "X_ood, y_ood = [],[]\n",
    "\n",
    "\n",
    "for data in tqdm(dataset_ood.dataloader):\n",
    "    img = data[0].numpy()\n",
    "    X_ood = np.reshape(img, (img.shape[0], img.shape[2], img.shape[3], img.shape[1]))\n",
    "\n",
    "    for x, pred in zip(X_ood, pred_ood):\n",
    "        monitor_pred, pdf = monitor_shine.predict(np.array([x]), pred, threshold_id)\n",
    "        m_pred.append(monitor_pred)\n",
    "        m_true.append(1) #monitor should always react to novel classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0e1c568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     49873\n",
      "           1       0.02      0.91      0.04       127\n",
      "\n",
      "    accuracy                           0.90     50000\n",
      "   macro avg       0.51      0.91      0.50     50000\n",
      "weighted avg       1.00      0.90      0.94     50000\n",
      "\n",
      "0.1350467623939485\n",
      "0.9065655899843872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "m_true = np.array(m_true)\n",
    "m_pred = np.array(m_pred).flatten()\n",
    "#evaluating SHINE\n",
    "\n",
    "print(classification_report(m_true, m_pred))\n",
    "print(mcc(m_true, m_pred))\n",
    "print(balanced_accuracy_score(m_true, m_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a18072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.9\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.12      0.13      0.13      9367\n",
    "           1       0.69      0.67      0.68     26665\n",
    "\n",
    "    accuracy                           0.53     36032\n",
    "   macro avg       0.40      0.40      0.40     36032\n",
    "weighted avg       0.54      0.53      0.53     36032\n",
    "\n",
    "-0.19622882233117975\n",
    "\n",
    "#0.1\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.05      0.04      0.05      9367\n",
    "           1       0.69      0.73      0.71     26665\n",
    "\n",
    "    accuracy                           0.55     36032\n",
    "   macro avg       0.37      0.39      0.38     36032\n",
    "weighted avg       0.52      0.55      0.54     36032\n",
    "\n",
    "-0.24099129213678386\n",
    "\n",
    "#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350143f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
