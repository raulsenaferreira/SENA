{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4b6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:27:16.806386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-30 17:27:16.806401: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import utils\n",
    "from dataset import Dataset\n",
    "from feature_extractor import FeatureExtractor\n",
    "from monitors_input import SHINE_monitor, SHINE_monitor2\n",
    "from monitors_internals import MahalanobisMonitor, OutsideTheBoxMonitor, MaxSoftmaxProbabilityMonitor,\\\n",
    "                    MaxLogitMonitor, EnergyMonitor, ReActMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3126fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../PRDC_2021_Data_profile_module/data/training_set/distributional_shift/cifar10/snow_severity_1\n",
      "(50000, 32, 32, 3) (50000,)\n"
     ]
    }
   ],
   "source": [
    "#model params\n",
    "batch_size = 10\n",
    "model = \"resnet\"\n",
    "\n",
    "#monitor params\n",
    "layer_relu_ids = [32]\n",
    "additional_transform = None\n",
    "adversarial_attack = None#\n",
    "\n",
    "#test dataset params\n",
    "threat_type = 'distributional_shift'\n",
    "variation = 'snow'\n",
    "severity = 1\n",
    "compl_path = '{}_severity_{}'.format(variation, severity)\n",
    "\n",
    "#train dataset params\n",
    "id_dataset = \"cifar10\"\n",
    "num_classes_id = 10\n",
    "\n",
    "#loading training set\n",
    "#(X_train, y_train), (X_val, y_val) = load_dataset(\n",
    "X_train, y_train = utils.load_dataset(\n",
    "    threat_type, compl_path, id_dataset, 'train', root_path='../PRDC_2021_Data_profile_module/data')#utils.load_data(id_dataset, None)\n",
    "X_train = X_train.astype('float32')\n",
    "#X_val = X_val.astype('float32')\n",
    "print(np.shape(X_train), np.shape(y_train))\n",
    "#print(np.shape(X_val), np.shape(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eebaee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset(compl_path, \"train\", model, (X_train, y_train), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712193e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting and storing features from test data using an ML model trained on ID data\n",
    "feature_extractor = FeatureExtractor(model, id_dataset, layer_relu_ids)\n",
    "features_train, logits_train, softmax_train, pred_train, lab_train = feature_extractor.get_features(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d21f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the monitors that use data from activation function layers\n",
    "id_layer_monitored = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building SHINE monitor\n",
    "# it can take a lot of time\n",
    "monitor_shine = SHINE_monitor(id_dataset)\n",
    "monitor_shine.fit(X_train, y_train, features_train[id_layer_monitored], pred_train)\n",
    "monitor_shine.name = 'shine'\n",
    "utils.save_monitors([monitor_shine], id_dataset)\n",
    "print('number of image density estimators',len(monitor_shine.arr_density_img))\n",
    "print('number of group of representative feature instances',len(monitor_shine.arr_repr_feature_TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2db5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building oob monitor\n",
    "monitor_oob = OutsideTheBoxMonitor(n_clusters=3)\n",
    "monitor_oob.name = 'oob'\n",
    "monitor_oob.fit(features_train[id_layer_monitored], lab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building react monitor\n",
    "monitor_react = ReActMonitor(quantile_value=0.99, mode='msp')\n",
    "monitor_react.name = 'react'\n",
    "monitor_react.fit(feature_extractor, features_train[id_layer_monitored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf647f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building softmax monitor\n",
    "monitor_msp = MaxSoftmaxProbabilityMonitor()\n",
    "monitor_msp.name = 'msp'\n",
    "monitor_msp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building max logit monitor\n",
    "monitor_maxlogits = MaxLogitMonitor()\n",
    "monitor_maxlogits.name = 'maxlogit'\n",
    "monitor_maxlogits.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ca152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building Energy monitor\n",
    "T = 1\n",
    "monitor_energy = EnergyMonitor(temperature=T)\n",
    "monitor_energy.name = 'energy'\n",
    "monitor_energy.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70099f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building mahalanobis monitor\n",
    "monitor_mahalanobis = MahalanobisMonitor(id_dataset, model, id_layer_monitored, is_tied=True)\n",
    "monitor_mahalanobis.name = 'mahalanobis'\n",
    "monitor_mahalanobis.fit(features_train[id_layer_monitored], lab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cf4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining thresholds for the monitors based on score\n",
    "# such thresholds are respecting a limit of 95% of scores on correct classified instances on ID dataset\n",
    "arr_thresholds_react = []\n",
    "arr_thresholds_msp = []\n",
    "arr_thresholds_logits = []\n",
    "arr_thresholds_energy = []\n",
    "arr_thresholds_mahalanobis = []\n",
    "arr_thresholds_shine = {'S':[], 'HINE':[]}\n",
    "\n",
    "for label in range(num_classes_id):\n",
    "    ind_cls = np.where(y_train==label) # for each class\n",
    "    ind_correct = np.where(y_train[ind_cls]==pred_train[ind_cls]) #take the correct classified instances\n",
    "    ind_incorrect = np.where(y_train[ind_cls]!=pred_train[ind_cls]) #take the INcorrect classified instances\n",
    "    \n",
    "    threshold = utils.calculate_threshold(monitor_react, label, features_train[id_layer_monitored][ind_correct])\n",
    "    arr_thresholds_react.append(threshold)\n",
    "    \n",
    "    threshold = utils.calculate_threshold(monitor_msp, label, softmax_train[ind_correct])\n",
    "    arr_thresholds_msp.append(threshold)\n",
    "    \n",
    "    threshold = utils.calculate_threshold(monitor_maxlogits, label, logits_train[ind_correct])\n",
    "    arr_thresholds_logits.append(threshold)\n",
    "    \n",
    "    threshold = utils.calculate_threshold(monitor_energy, label, logits_train[ind_correct])\n",
    "    arr_thresholds_energy.append(threshold)\n",
    "    \n",
    "    threshold = utils.calculate_threshold(monitor_mahalanobis, label, features_train[id_layer_monitored][ind_correct])\n",
    "    arr_thresholds_mahalanobis.append(threshold)\n",
    "    \n",
    "    # SHINE uses info from both correct (features) and incorrect (images) classified instances from a class\n",
    "    threshold_S, threshold_HINE = utils.calculate_threshold_SHINE(monitor_shine, X_train[ind_incorrect], label, \n",
    "                                                                  pred_train[ind_cls], \n",
    "                                                                  features_train[id_layer_monitored][ind_cls])\n",
    "    arr_thresholds_shine['S'].append(threshold_S)\n",
    "    arr_thresholds_shine['HINE'].append(threshold_HINE)\n",
    "    \n",
    "    \n",
    "# attributing array of calculated thresholds for each monitor\n",
    "monitor_react.arr_thresholds = arr_thresholds_react\n",
    "monitor_msp.arr_thresholds = arr_thresholds_msp\n",
    "monitor_maxlogits.arr_thresholds = arr_thresholds_logits\n",
    "monitor_energy.arr_thresholds = arr_thresholds_energy\n",
    "monitor_mahalanobis.arr_thresholds = arr_thresholds_mahalanobis\n",
    "monitor_shine.arr_thresholds = arr_thresholds_shine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f36fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving monitors\n",
    "arr_monitors = []\n",
    "arr_monitors.append(monitor_oob)\n",
    "arr_monitors.append(monitor_react)\n",
    "arr_monitors.append(monitor_msp)\n",
    "arr_monitors.append(monitor_maxlogits)\n",
    "arr_monitors.append(monitor_energy)\n",
    "arr_monitors.append(monitor_mahalanobis)\n",
    "arr_monitors.append(monitor_shine)\n",
    "\n",
    "utils.save_monitors(arr_monitors, id_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "553ccf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitor reaction True\n",
      "monitor reaction True\n",
      "monitor reaction True\n",
      "monitor reaction False\n",
      "monitor reaction True\n",
      "monitor reaction True\n",
      "monitor reaction True\n",
      "monitor reaction True\n",
      "monitor reaction True\n",
      "monitor reaction True\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: test if the monitors were correctly saved\n",
    "import os\n",
    "import pickle\n",
    "monitor_name = 'react'\n",
    "num_instances = 10 # testing with 10 instances\n",
    "monitor_filename = os.path.join('Monitors', id_dataset, '{}.sav'.format(monitor_name))\n",
    "monitor = pickle.load(open(monitor_filename, 'rb'))\n",
    "\n",
    "for x, pred, feature, softmax, logits, label in zip(X_train[:num_instances], pred_train[:num_instances], \n",
    "                                                    features_train[id_layer_monitored][:num_instances],\n",
    "                                                 softmax_train[:num_instances], logits_train[:num_instances],\n",
    "                                                    y_train[:num_instances]):\n",
    "    \n",
    "    m_score = monitor.predict(np.array([feature]))[0]\n",
    "    m_pred = m_score<=monitor.arr_thresholds[pred]\n",
    "    print('monitor reaction', m_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e52489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "False\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "True\n",
      "(1, 32, 32, 3)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: test if SHINE monitor was correctly saved\n",
    "import os\n",
    "import pickle\n",
    "monitor_name = 'shine'\n",
    "num_instances = 10 # testing with 10 instances\n",
    "monitor_filename = os.path.join('Monitors', id_dataset, '{}.sav'.format(monitor_name))\n",
    "monitor = pickle.load(open(monitor_filename, 'rb'))\n",
    "\n",
    "for x, pred, feature, softmax, logits, label in zip(X_train[:num_instances], pred_train[:num_instances], \n",
    "                                                    features_train[id_layer_monitored][:num_instances],\n",
    "                                                 softmax_train[:num_instances], logits_train[:num_instances],\n",
    "                                                    y_train[:num_instances]):\n",
    "    \n",
    "    \n",
    "    avg_sim_TP, logprob = monitor.predict(np.array([x]), feature, pred)\n",
    "    if avg_sim_TP >= monitor.arr_thresholds['S'][pred]['TP']:\n",
    "        print(False) \n",
    "    elif avg_sim_TP <= monitor.arr_thresholds['S'][pred]['FN']:\n",
    "        print(True)\n",
    "    else:\n",
    "        print(np.exp(logprob) <= monitor.arr_thresholds['HINE'][pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
