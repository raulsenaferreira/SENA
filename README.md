# SENA
Repository of the paper "Similarity-based Error-checking of Neural Activations"

OOD data is usually source of errors in classifiers and object detectors built with deep learning.
Literature usually apply detectors at real-time aiming at detect and avoid such data.
However, not all OOD data exposed to the ML model will yield wrong predictions. 
To avoid wrong ML predictions at real-time, we developed this safety monitor which the goal is to detect when the ML model outputs a unreliable prediction.
